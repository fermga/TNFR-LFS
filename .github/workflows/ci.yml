name: CI

on:
  push:
    branches: [main]
  pull_request:

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: false

jobs:
  detect-changes:
    name: Detect changes
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate.outputs.matrix }}
      changes: ${{ steps.filter.outputs.changes }}
      full_suite_on_main: ${{ steps.determine-pytest.outputs.full_suite_on_main }}
      run_full_suite: ${{ steps.determine-pytest.outputs.run_full_suite }}
      should_run_tests: ${{ steps.determine-pytest.outputs.should_run_tests }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.sha }}
          fetch-depth: 0
      - name: Generate test areas
        id: generate
        run: |
          python - <<'PY'
          import json
          import os
          import subprocess
          import sys
          from pathlib import Path

          try:
              import yaml
          except ModuleNotFoundError:
              subprocess.check_call([sys.executable, "-m", "pip", "install", "pyyaml"])
              import yaml

          data = yaml.safe_load(Path(".github/test-areas.yml").read_text(encoding="utf-8"))
          areas = data.get("areas", [])

          filters = {}
          matrix = []
          for area in areas:
              name = area["name"]
              filters[name] = area.get("filter_globs", [])

              include = area.get("include_in_matrix")
              pytest_args = area.get("pytest_args")
              if include is None:
                  include = pytest_args is not None
              if not include:
                  continue

              args = pytest_args or []
              if isinstance(args, str):
                  args = [args]

              matrix.append(
                  {
                      "area": name,
                      "display_name": area.get("display_name", name),
                      "pytest_args": " ".join(args),
                      "run": area.get("run_output", name),
                  }
              )

          matrix.append(
              {
                  "area": "full",
                  "display_name": "full",
                  "pytest_args": "",
                  "run": "full_suite_on_main",
              }
          )

          filters_yaml = yaml.safe_dump(filters, sort_keys=False)
          matrix_obj = {"include": matrix}
          matrix_json = json.dumps(matrix_obj, separators=(",", ":"))

          output_path = Path(os.environ["GITHUB_OUTPUT"])
          with output_path.open("a", encoding="utf-8") as fh:
              fh.write("filters<<EOF\n")
              fh.write(filters_yaml)
              if not filters_yaml.endswith("\n"):
                  fh.write("\n")
              fh.write("EOF\n")
              fh.write(f"matrix={matrix_json}\n")
          PY
      - id: filter
        uses: dorny/paths-filter@v3
        with:
          # Each filter mirrors a logical product area sourced from
          # .github/test-areas.yml so updating that file keeps detection and
          # pytest selection aligned.
          filters: ${{ steps.generate.outputs.filters }}
      - name: Determine pytest selection
        id: determine-pytest
        env:
          CHANGED_AREAS: ${{ steps.filter.outputs.changes }}
          IS_MAIN: ${{ github.ref == 'refs/heads/main' }}
        run: |
          python - <<'PY'
          import json
          import os

          raw_changes = json.loads(os.environ["CHANGED_AREAS"])
          if isinstance(raw_changes, dict):
              changes = [name for name, changed in raw_changes.items() if changed]
          else:
              changes = list(raw_changes)
          is_main = os.environ["IS_MAIN"].lower() == "true"

          run_full_suite = not changes
          full_suite = is_main
          should_run = full_suite or run_full_suite or bool(changes)

          with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as fh:
              fh.write(f"full_suite_on_main={'true' if full_suite else 'false'}\n")
              fh.write(f"run_full_suite={'true' if run_full_suite else 'false'}\n")
              fh.write(f"should_run_tests={'true' if should_run else 'false'}\n")
          PY


  test:
    needs: detect-changes
    if: >-
      ${{
        needs.detect-changes.outputs.should_run_tests == 'true' &&
        (
          (
            matrix.run == 'full_suite_on_main' &&
            (
              needs.detect-changes.outputs.full_suite_on_main == 'true' ||
              needs.detect-changes.outputs.run_full_suite == 'true'
            )
          ) ||
          contains(fromJson(needs.detect-changes.outputs.changes), matrix.run) ||
          contains(fromJson(needs.detect-changes.outputs.changes), matrix.area)
        )
      }}
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{ fromJson(needs.detect-changes.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.sha }}
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: |
            pyproject.toml
      - name: Install dependencies
        run: |
          # Install project + dev extras (brings in numpy/pandas before pytest)
          pip install .[dev]
      - name: Ruff
        run: ruff check .
      - name: Mypy
        run: mypy --strict
      - name: Publish pytest selection
        env:
          PYTEST_ARGS: ${{ matrix.pytest_args }}
          PYTEST_AREA: ${{ matrix.display_name }}
        run: |
          if [[ -z "$PYTEST_ARGS" ]]; then
            echo "* **${PYTEST_AREA}** → full suite" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "* **${PYTEST_AREA}** → ${PYTEST_ARGS}" >> "$GITHUB_STEP_SUMMARY"
          fi
      - name: Pytest
        env:
          PYTEST_ARGS: ${{ matrix.pytest_args }}
          PYTEST_AREA: ${{ matrix.area }}
        run: |
          set -euo pipefail

          if [[ -z "$PYTEST_ARGS" ]]; then
            echo "Running full pytest suite"
            pytest -q --cov=tnfr_lfs --cov-report=xml --cov-report=term-missing
          else
            echo "Running targeted pytest selection for area '$PYTEST_AREA': $PYTEST_ARGS"
            pytest -q --cov=tnfr_lfs --cov-report=xml --cov-report=term-missing $PYTEST_ARGS
          fi
      - name: Upload coverage report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-xml
          path: coverage.xml
  link-check:
    name: Documentation links
    needs: detect-changes
    if: >-
      contains(fromJson(needs.detect-changes.outputs.changes), 'docs') ||
      github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.sha }}
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Check documentation language
        run: make docs-language-check
      - name: Check documentation links
        uses: lycheeverse/lychee-action@v1
        with:
          args: >-
            --config lychee.toml
            --no-progress
            --verbose
            README.md
            docs/**/*.md

  quickstart:
    needs:
      - detect-changes
    if: >-
      github.ref == 'refs/heads/main' ||
      contains(fromJson(needs.detect-changes.outputs.changes), 'examples')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.sha }}
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: |
            pyproject.toml
      - name: Install dependencies
        run: |
          # Install project + dev extras (brings in numpy/pandas before pytest)
          pip install .[dev]
      - name: Quickstart (simulated pipeline)
        run: make quickstart

  theory-audit:
    name: Theory audit
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.sha }}
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Run theory audit
        run: |
          python -m tools.tnfr_theory_audit --core --tests --output tests/_report/theory_impl_matrix.md
      - name: Upload theory implementation matrix
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: theory-impl-matrix
          path: |
            tests/_report/theory_impl_matrix.md
            tests/_report/.gitkeep
          if-no-files-found: warn
